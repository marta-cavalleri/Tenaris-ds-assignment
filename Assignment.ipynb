{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install requirements before running this notebook\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import requested libraries\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database parameters\n",
    "\n",
    "HOST = '***'\n",
    "PORT = 25060\n",
    "USERNAME = '***'\n",
    "PASSWORD =  '***'\n",
    "DATABASE = 'interview'\n",
    "#FLAGS : sslmode=require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Query PostgreSQL:\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(user = USERNAME,\n",
    "                                  password = PASSWORD,\n",
    "                                  host = HOST,\n",
    "                                  port = PORT,\n",
    "                                  database = DATABASE,\n",
    "                                  sslmode = 'require')\n",
    "    # Connection to PostgreSQL\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # 1st Query Execution: input features table\n",
    "    query_regressors = 'SELECT * from ccpp.regressors'\n",
    "    cursor.execute(query_regressors)\n",
    "    record_reg = cursor.fetchall()\n",
    "    cur_desc = cursor.description\n",
    "    column_names=[]\n",
    "    for col in cur_desc:\n",
    "        column_names.append(col.name)\n",
    "    \n",
    "    # 2nd Query Execution: target table\n",
    "    query_target = 'SELECT * from ccpp.target'\n",
    "    cursor.execute(query_target)\n",
    "    record_target = cursor.fetchall()\n",
    "       \n",
    "except (Exception, psycopg2.Error) as error :\n",
    "    print (\"Error while connecting to PostgreSQL\", error)\n",
    "finally:\n",
    "    # Closing database connection\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(record_reg, columns=['ID','AT','V','AP','RH'])\n",
    "print(X.head())\n",
    "print(X.shape)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(record_target, columns=['ID','PE'])\n",
    "print(Y.head())\n",
    "print(Y.shape)\n",
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(X, Y, on='ID', how='inner')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check intersection of IDs\n",
    "assert len(list(set(X.ID) & set(Y.ID)))==df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas profiling for a first deep dive into data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile_reg = pandas_profiling.ProfileReport(X)\n",
    "profile_reg.to_file(outputfile=\"input_regressor_report.html\")\n",
    "\n",
    "profile_tgt = pandas_profiling.ProfileReport(Y)\n",
    "profile_tgt.to_file(outputfile=\"target_report.html\")\n",
    "\n",
    "profile = pandas_profiling.ProfileReport(df)\n",
    "profile.to_file(outputfile=\"complete_dataset_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From analysis in report:\n",
    "* from the Spearman correlation heatmap we can see that **V and AT are strongly correlated to each other**\n",
    "* from the same heatmap we can see that **AT is strongly and negativly correlated to target PE**. So does V.\n",
    "* Distribution of AP and PE need to be investigated: **possible outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_features = ['AT', 'V', 'AP', 'RH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with missing values\n",
    "From report analysis: \n",
    "* one missing value in target --> remove row\n",
    "* one missing value in AT --> Fill element (scikit learn provides SimpleImputer or IterativeImputer -beta-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop row with missing value in target variable\n",
    "print(df[np.isnan(df.PE)])\n",
    "df.drop(df[np.isnan(df.PE)].index[0], axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check that AT is the only field with nan values\n",
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill na values with SimpleImputer. Best is IterativeImputer but it is in beta release\n",
    "df_columns=df.columns\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df_array = imp.fit_transform(df)  \n",
    "df = pd.DataFrame(df_array, columns=df_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove oultiers from each field. \n",
    "\n",
    "From analysis in pandas profiling, let's investigate AP first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution plot  and boxplot of AP\n",
    "fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(8,3))\n",
    "sns.distplot(df.AP, ax=axes[0])\n",
    "sns.boxplot(df.AP, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove the row with outliers in dataframe\n",
    "print(df[df['AP']>=10000])\n",
    "df.drop(df[df['AP']>=10000].index[0],axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check distribution plot  and boxplot of AP. Are there more outliers? NO\n",
    "fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(8,3))\n",
    "sns.distplot(df.AP, ax=axes[0])\n",
    "sns.boxplot(df.AP, ax=axes[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution plots to find possible outliers for the remaining fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=4,figsize=(16,4))\n",
    "for ax, col in zip(axes, input_features):\n",
    "    sns.distplot(df[col], ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what about target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "sns.boxplot(df.PE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Target variable has one outlier: remove it from the dataframe\n",
    "df.drop(df[df.PE>400000].index[0], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "sns.distplot(df.PE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see trends and correlations in the pairgrid plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(df[input_features+['PE']])\n",
    "g.map_diag(plt.hist)\n",
    "g.map_offdiag(plt.scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily see how AT and the target variable PE are strongly correlated. We can suppose that AT is one of the most important variables in predicting PE. Let's check it with some regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standardize all features before applying regression models, specially for linera regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = df.PE\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[input_features])\n",
    "print(scaler.mean_)\n",
    "X_input=pd.DataFrame(scaler.transform(df[input_features]), columns=input_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries from scikit-learn. Let's first test some classical machine learning models.\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linear regression model, evaluated with 10-fold cross validation\n",
    "CV=10\n",
    "reg = LinearRegression().fit(X_input, target)\n",
    "np.mean(cross_val_score(reg, X_input, target, scoring='r2',cv=CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get variable importance from coefficients set by the regression model for each input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_coeff = [(x,y) for x,y in zip(input_features,reg.coef_)]\n",
    "reg_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression model confirms that AT is the most important feature for the PE prediction. Its importance was already known by the Spearman correlation coefficient between AT and Target PE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare more models in order to estimate the best performance. (GridSearchCV should be applied to check different hyperparameters configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "sgd.fit(X_input, target)\n",
    "print(\"Mean R2 score over {}-folds {}\".format(CV,np.mean(np.mean(cross_val_score(sgd, X_input, target, scoring='r2',cv=CV)))))\n",
    "sgd_coeff = [(x,y) for x,y in zip(input_features,sgd.coef_)]\n",
    "sgd_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=8, random_state=42,  n_estimators=100)\n",
    "rfr.fit(X_input,target)\n",
    "print(\"Mean R2 score over {}-folds {}\".format(CV,np.mean(cross_val_score(rfr, X_input, target, scoring='r2',cv=CV))))\n",
    "rfr_feature_imp = [(x,y) for x,y in zip(input_features,rfr.feature_importances_)]\n",
    "rfr_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "xgb = xgboost.XGBRegressor(max_depth=8, n_estimators=100, booster='gbtree', random_state=42, verbosity=0)\n",
    "#xgb.fit(X_input,target)\n",
    "mean_xgb_score=np.mean(np.mean(cross_val_score(xgb, X_input, target, scoring='r2',cv=CV)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Mean R2 score over {}-folds {}\".format(CV,mean_xgb_score))\n",
    "xgb_feature_imp = [(x,y) for x,y in zip(input_features,xgb.feature_importances_)]\n",
    "xgb_feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is the model with the best performance on the provided dataset. The feature importance got from this model confirms the relevance of AT in predicting PE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
